{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "## Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = Path('Resources/LoanStats_2019Q1.csv')\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    " \n",
    "X = pd.get_dummies(df.drop(columns='loan_status'))\n",
    "\n",
    "# Create our target\n",
    "y = df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>...</th>\n",
       "      <th>issue_d_Mar-2019</th>\n",
       "      <th>pymnt_plan_n</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>next_pymnt_d_Apr-2019</th>\n",
       "      <th>next_pymnt_d_May-2019</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>hardship_flag_N</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>6.881700e+04</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.0</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.000000</td>\n",
       "      <td>68817.0</td>\n",
       "      <td>68817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16677.594562</td>\n",
       "      <td>0.127718</td>\n",
       "      <td>480.652863</td>\n",
       "      <td>8.821371e+04</td>\n",
       "      <td>21.778153</td>\n",
       "      <td>0.217766</td>\n",
       "      <td>0.497697</td>\n",
       "      <td>12.587340</td>\n",
       "      <td>0.126030</td>\n",
       "      <td>17604.142828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.123879</td>\n",
       "      <td>0.876121</td>\n",
       "      <td>0.383161</td>\n",
       "      <td>0.616839</td>\n",
       "      <td>0.860340</td>\n",
       "      <td>0.139660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10277.348590</td>\n",
       "      <td>0.048130</td>\n",
       "      <td>288.062432</td>\n",
       "      <td>1.155800e+05</td>\n",
       "      <td>20.199244</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.758122</td>\n",
       "      <td>6.022869</td>\n",
       "      <td>0.336797</td>\n",
       "      <td>21835.880400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329446</td>\n",
       "      <td>0.329446</td>\n",
       "      <td>0.486161</td>\n",
       "      <td>0.486161</td>\n",
       "      <td>0.346637</td>\n",
       "      <td>0.346637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>30.890000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9000.000000</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>265.730000</td>\n",
       "      <td>5.000000e+04</td>\n",
       "      <td>13.890000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6293.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>404.560000</td>\n",
       "      <td>7.300000e+04</td>\n",
       "      <td>19.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12068.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24000.000000</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>648.100000</td>\n",
       "      <td>1.040000e+05</td>\n",
       "      <td>26.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21735.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>1676.230000</td>\n",
       "      <td>8.797500e+06</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>587191.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt      int_rate   installment    annual_inc           dti  \\\n",
       "count  68817.000000  68817.000000  68817.000000  6.881700e+04  68817.000000   \n",
       "mean   16677.594562      0.127718    480.652863  8.821371e+04     21.778153   \n",
       "std    10277.348590      0.048130    288.062432  1.155800e+05     20.199244   \n",
       "min     1000.000000      0.060000     30.890000  4.000000e+01      0.000000   \n",
       "25%     9000.000000      0.088100    265.730000  5.000000e+04     13.890000   \n",
       "50%    15000.000000      0.118000    404.560000  7.300000e+04     19.760000   \n",
       "75%    24000.000000      0.155700    648.100000  1.040000e+05     26.660000   \n",
       "max    40000.000000      0.308400   1676.230000  8.797500e+06    999.000000   \n",
       "\n",
       "        delinq_2yrs  inq_last_6mths      open_acc       pub_rec  \\\n",
       "count  68817.000000    68817.000000  68817.000000  68817.000000   \n",
       "mean       0.217766        0.497697     12.587340      0.126030   \n",
       "std        0.718367        0.758122      6.022869      0.336797   \n",
       "min        0.000000        0.000000      2.000000      0.000000   \n",
       "25%        0.000000        0.000000      8.000000      0.000000   \n",
       "50%        0.000000        0.000000     11.000000      0.000000   \n",
       "75%        0.000000        1.000000     16.000000      0.000000   \n",
       "max       18.000000        5.000000     72.000000      4.000000   \n",
       "\n",
       "           revol_bal  ...  issue_d_Mar-2019  pymnt_plan_n  \\\n",
       "count   68817.000000  ...      68817.000000       68817.0   \n",
       "mean    17604.142828  ...          0.177238           1.0   \n",
       "std     21835.880400  ...          0.381873           0.0   \n",
       "min         0.000000  ...          0.000000           1.0   \n",
       "25%      6293.000000  ...          0.000000           1.0   \n",
       "50%     12068.000000  ...          0.000000           1.0   \n",
       "75%     21735.000000  ...          0.000000           1.0   \n",
       "max    587191.000000  ...          1.000000           1.0   \n",
       "\n",
       "       initial_list_status_f  initial_list_status_w  next_pymnt_d_Apr-2019  \\\n",
       "count           68817.000000           68817.000000           68817.000000   \n",
       "mean                0.123879               0.876121               0.383161   \n",
       "std                 0.329446               0.329446               0.486161   \n",
       "min                 0.000000               0.000000               0.000000   \n",
       "25%                 0.000000               1.000000               0.000000   \n",
       "50%                 0.000000               1.000000               0.000000   \n",
       "75%                 0.000000               1.000000               1.000000   \n",
       "max                 1.000000               1.000000               1.000000   \n",
       "\n",
       "       next_pymnt_d_May-2019  application_type_Individual  \\\n",
       "count           68817.000000                 68817.000000   \n",
       "mean                0.616839                     0.860340   \n",
       "std                 0.486161                     0.346637   \n",
       "min                 0.000000                     0.000000   \n",
       "25%                 0.000000                     1.000000   \n",
       "50%                 1.000000                     1.000000   \n",
       "75%                 1.000000                     1.000000   \n",
       "max                 1.000000                     1.000000   \n",
       "\n",
       "       application_type_Joint App  hardship_flag_N  debt_settlement_flag_N  \n",
       "count                68817.000000          68817.0                 68817.0  \n",
       "mean                     0.139660              1.0                     1.0  \n",
       "std                      0.346637              0.0                     0.0  \n",
       "min                      0.000000              1.0                     1.0  \n",
       "25%                      0.000000              1.0                     1.0  \n",
       "50%                      0.000000              1.0                     1.0  \n",
       "75%                      0.000000              1.0                     1.0  \n",
       "max                      1.000000              1.0                     1.0  \n",
       "\n",
       "[8 rows x 95 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low_risk     68470\n",
       "high_risk      347\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51612, 95)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the X and y into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "X_train.shape\n",
    "#y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "Scale the training and testing data using the `StandardScaler` from `sklearn`. Remember that when scaling the data, you only scale the features data (`X_train` and `X_testing`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "# When fitting scaling functions, only train on the training dataset\n",
    "scaler_X = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training and testing data\n",
    "X_train = scaler_X.transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learners\n",
    "\n",
    "In this section, you will compare two ensemble algorithms to determine which algorithm results in the best performance. You will train a Balanced Random Forest Classifier and an Easy Ensemble classifier . For each algorithm, be sure to complete the folliowing steps:\n",
    "\n",
    "1. Train the model using the training data. \n",
    "2. Calculate the balanced accuracy score from sklearn.metrics.\n",
    "3. Display the confusion matrix from sklearn.metrics.\n",
    "4. Generate a classication report using the `imbalanced_classification_report` from imbalanced-learn.\n",
    "5. For the Balanced Random Forest Classifier only, print the feature importance sorted in descending order (most important feature to least important) along with the feature score\n",
    "\n",
    "Note: Use a random state of 1 for each algorithm to ensure consistency between tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_model = RandomForestClassifier(n_estimators=1000,\n",
    "                random_state=1,\n",
    "                class_weight='balanced'\n",
    ")\n",
    "random_model = random_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6146796475579245"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "predictions_random_model = random_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "random_forest_score = balanced_accuracy_score(y_test, predictions_random_model)\n",
    "\n",
    "random_forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_high_risk</th>\n",
       "      <th>prediction_low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_high_risk</th>\n",
       "      <td>20</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_low_risk</th>\n",
       "      <td>9</td>\n",
       "      <td>17109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  prediction_high_risk  prediction_low_risk\n",
       "actual_high_risk                    20                   67\n",
       "actual_low_risk                      9                17109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cf_mtrx = confusion_matrix(y_test, predictions_random_model) \n",
    "\n",
    "confusion_df = pd.DataFrame(cf_mtrx, index=[\"actual_high_risk\", \"actual_low_risk\"], columns=[\"prediction_high_risk\", \"prediction_low_risk\"])\n",
    "\n",
    "display(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.69      0.23      1.00      0.34      0.48      0.21        87\n",
      "   low_risk       1.00      1.00      0.23      1.00      0.48      0.25     17118\n",
      "\n",
      "avg / total       0.99      1.00      0.23      0.99      0.48      0.25     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, predictions_random_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.07664503777777659, 'total_rec_prncp'),\n",
       " (0.06696157853955453, 'total_rec_int'),\n",
       " (0.0661299701435517, 'total_pymnt_inv'),\n",
       " (0.06211044240334791, 'last_pymnt_amnt'),\n",
       " (0.059205774609013447, 'total_pymnt'),\n",
       " (0.027542966135633815, 'int_rate'),\n",
       " (0.02604764697883617, 'issue_d_Jan-2019'),\n",
       " (0.020481985645746187, 'issue_d_Mar-2019'),\n",
       " (0.019549371124393828, 'installment'),\n",
       " (0.017814617862977042, 'out_prncp_inv'),\n",
       " (0.017295431677141287, 'annual_inc'),\n",
       " (0.016985530227039934, 'dti'),\n",
       " (0.016946551973067592, 'out_prncp'),\n",
       " (0.015176957894777514, 'max_bal_bc'),\n",
       " (0.015098929976123058, 'mths_since_recent_inq'),\n",
       " (0.014925239032039773, 'avg_cur_bal'),\n",
       " (0.014451343673168943, 'mo_sin_old_rev_tl_op'),\n",
       " (0.014131309394034878, 'mo_sin_old_il_acct'),\n",
       " (0.014099065589447313, 'revol_bal'),\n",
       " (0.014067922113232378, 'il_util'),\n",
       " (0.0139535832479391, 'bc_util'),\n",
       " (0.013592291994524176, 'tot_hi_cred_lim'),\n",
       " (0.01331399263000389, 'bc_open_to_buy'),\n",
       " (0.0130778494190126, 'total_bc_limit'),\n",
       " (0.012805994312364285, 'tot_cur_bal'),\n",
       " (0.012332060360226162, 'all_util'),\n",
       " (0.012147602517564212, 'loan_amnt'),\n",
       " (0.011928272675959235, 'total_bal_ex_mort'),\n",
       " (0.011903046713564382, 'mths_since_rcnt_il'),\n",
       " (0.011864224228696998, 'total_bal_il'),\n",
       " (0.011854939027456423, 'total_rev_hi_lim'),\n",
       " (0.011105724423968653, 'mths_since_recent_bc'),\n",
       " (0.010719670121731832, 'total_il_high_credit_limit'),\n",
       " (0.009820069604345165, 'total_rec_late_fee'),\n",
       " (0.009667832054158491, 'mo_sin_rcnt_rev_tl_op'),\n",
       " (0.009557433213166329, 'total_acc'),\n",
       " (0.008882061565833349, 'pct_tl_nvr_dlq'),\n",
       " (0.008841960470928539, 'num_rev_accts'),\n",
       " (0.008482065719015157, 'open_acc'),\n",
       " (0.00816039595755428, 'num_il_tl'),\n",
       " (0.008055223479859088, 'num_sats'),\n",
       " (0.00777250651803617, 'mo_sin_rcnt_tl'),\n",
       " (0.007420006422100005, 'inq_last_12m'),\n",
       " (0.007413680888289981, 'num_actv_rev_tl'),\n",
       " (0.007362561298275275, 'num_rev_tl_bal_gt_0'),\n",
       " (0.007321834356057523, 'num_actv_bc_tl'),\n",
       " (0.007166588823294409, 'num_bc_tl'),\n",
       " (0.007066584274105501, 'issue_d_Feb-2019'),\n",
       " (0.006925093070003805, 'num_op_rev_tl'),\n",
       " (0.006877611346864529, 'acc_open_past_24mths'),\n",
       " (0.006833433248479752, 'next_pymnt_d_May-2019'),\n",
       " (0.006743592279180552, 'total_cu_tl'),\n",
       " (0.006671196787900855, 'next_pymnt_d_Apr-2019'),\n",
       " (0.006004784443708718, 'percent_bc_gt_75'),\n",
       " (0.005947994569724764, 'num_bc_sats'),\n",
       " (0.00589826550839641, 'inq_fi'),\n",
       " (0.005628141692378056, 'mort_acc'),\n",
       " (0.005526498751352546, 'open_rv_24m'),\n",
       " (0.005435282277357239, 'num_tl_op_past_12m'),\n",
       " (0.005215064473145379, 'open_il_24m'),\n",
       " (0.005210335523706468, 'open_act_il'),\n",
       " (0.004851232448906347, 'inq_last_6mths'),\n",
       " (0.0038195795855725527, 'open_acc_6m'),\n",
       " (0.0036329225622940826, 'delinq_2yrs'),\n",
       " (0.0034032677235554193, 'open_il_12m'),\n",
       " (0.0032254820866091747, 'open_rv_12m'),\n",
       " (0.002520366687496172, 'tot_coll_amt'),\n",
       " (0.002487556676303674, 'num_accts_ever_120_pd'),\n",
       " (0.002155738979616332, 'verification_status_Verified'),\n",
       " (0.0017962536963704266, 'home_ownership_OWN'),\n",
       " (0.0017306972195145146, 'verification_status_Not Verified'),\n",
       " (0.0017007768149773417, 'home_ownership_RENT'),\n",
       " (0.0014797122317045123, 'verification_status_Source Verified'),\n",
       " (0.001398849878204981, 'pub_rec_bankruptcies'),\n",
       " (0.0013140835441996018, 'pub_rec'),\n",
       " (0.00121590209716339, 'home_ownership_MORTGAGE'),\n",
       " (0.0009725362622238893, 'application_type_Joint App'),\n",
       " (0.0009425828817978745, 'application_type_Individual'),\n",
       " (0.0008810242332154019, 'num_tl_90g_dpd_24m'),\n",
       " (0.0008521251581952355, 'initial_list_status_w'),\n",
       " (0.0007820022480165095, 'initial_list_status_f'),\n",
       " (0.0002901330281889133, 'collections_12_mths_ex_med'),\n",
       " (0.00027075069770826415, 'home_ownership_ANY'),\n",
       " (0.00010131991412341582, 'chargeoff_within_12_mths'),\n",
       " (8.028290789030615e-08, 'delinq_amnt'),\n",
       " (0.0, 'tax_liens'),\n",
       " (0.0, 'recoveries'),\n",
       " (0.0, 'pymnt_plan_n'),\n",
       " (0.0, 'policy_code'),\n",
       " (0.0, 'num_tl_30dpd'),\n",
       " (0.0, 'num_tl_120dpd_2m'),\n",
       " (0.0, 'hardship_flag_N'),\n",
       " (0.0, 'debt_settlement_flag_N'),\n",
       " (0.0, 'collection_recovery_fee'),\n",
       " (0.0, 'acc_now_delinq')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importance_list = sorted(zip(random_model.feature_importances_, X.columns), reverse=True)\n",
    "\n",
    "importance_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Classifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "#the model\n",
    "easy_classifier = EasyEnsembleClassifier(n_estimators=1000, random_state=1)\n",
    "easy_classifier = easy_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265665099451676"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "easy_classifier_predictions = easy_classifier.predict(X_test) \n",
    "\n",
    "easy_classifier_score = balanced_accuracy_score(y_test, easy_classifier_predictions)\n",
    "\n",
    "easy_classifier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_high_risk</th>\n",
       "      <th>prediction_low_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_high_risk</th>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_low_risk</th>\n",
       "      <td>940</td>\n",
       "      <td>16178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  prediction_high_risk  prediction_low_risk\n",
       "actual_high_risk                    79                    8\n",
       "actual_low_risk                    940                16178"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cf_mtrx = confusion_matrix(y_test, easy_classifier_predictions)\n",
    "\n",
    "confusion_df = pd.DataFrame( cf_mtrx, index=[\"actual_high_risk\", \"actual_low_risk\"], columns=[\"prediction_high_risk\", \"prediction_low_risk\"])\n",
    "\n",
    "display(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "  high_risk       0.08      0.91      0.95      0.14      0.93      0.86        87\n",
      "   low_risk       1.00      0.95      0.91      0.97      0.93      0.86     17118\n",
      "\n",
      "avg / total       0.99      0.94      0.91      0.97      0.93      0.86     17205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, easy_classifier_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The easy ensemble classifier model had the best balanced accuracy score as True\n",
      "The easy ensemble classifier model had the best recall score with scoring 0.91 for high risk and 0.95 for low risk, which are higher than that of random forest classifier model which were 1.00 for high risk, and 0.23 for low risk\n",
      "The easy ensemble classifier model had the best geometric score with 0.93\n",
      "      top_features\n",
      "0  total_rec_prncp\n",
      "1    total_rec_int\n",
      "2  total_pymnt_inv\n"
     ]
    }
   ],
   "source": [
    "### Final Questions\n",
    "\n",
    "#1. Which model had the best balanced accuracy score?\n",
    "\n",
    "if random_forest_score > easy_classifier_score:\n",
    "    print(f\"The random forest classifer model had the best balanced accuracy score as {random_forest_score > easy_classifier_score} \")\n",
    "elif easy_classifier_score > random_forest_score:\n",
    "    print(f\"The easy ensemble classifier model had the best balanced accuracy score as {easy_classifier_score > random_forest_score}\")\n",
    "else:\n",
    "    print(\"Both models had the same score\")\n",
    "#2. Which model had the best recall score?\n",
    "print(\"The easy ensemble classifier model had the best recall score with scoring 0.91 for high risk and 0.95 for low risk, which are higher than that of random forest classifier model which were 1.00 for high risk, and 0.23 for low risk\")\n",
    "\n",
    "#3. Which model had the best geometric mean score?\n",
    "print(\"The easy ensemble classifier model had the best geometric score with 0.93\")\n",
    "\n",
    "#4. What are the top three features?\n",
    "importance_list = list(importance_list)\n",
    "#display(importance_list)\n",
    "importance_list = pd.DataFrame(importance_list)\n",
    "importance_list = importance_list.rename(columns={1:'top_features'}).drop(columns={0})\n",
    "print(f\"{importance_list[:3]}\")\n",
    "#importance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
